# LlamaEdgeEmbeddings
Local inference engine

[LlamgeEdge](https://llamaedge.com)+[llama-api-server](https://github.com/LlamaEdge/LlamaEdge/tree/main/llama-api-server).

* Without [Stable Diffusion](https://github.com/LlamaEdge/sd-api-server) which is for Apple Silicon only.
